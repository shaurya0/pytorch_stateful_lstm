{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shaur\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "from time import sleep\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1200\n",
    "batch_size = 32\n",
    "seq_len = 20\n",
    "num_features = 1\n",
    "window_size = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, seq_len):\n",
    "    N_train = int(N*0.8)\n",
    "    X = np.zeros((N, seq_len), dtype=np.float32)\n",
    "    y = np.zeros((N,1), dtype=np.float32)\n",
    "    \n",
    "    indices = np.random.randint(0, N, size=N//2)\n",
    "    \n",
    "    X[indices, 0] = 1.0\n",
    "    y[indices, 0] = 1.0\n",
    "    \n",
    "    X_train, y_train = X[:N_train], y[:N_train]\n",
    "    X_test, y_test = X[N_train:], y[N_train:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_test_data(N, seq_len):\n",
    "    N_train = int(N*0.8)\n",
    "    X = np.reshape(np.arange(0, N*seq_len, dtype=np.float32),(N, seq_len))\n",
    "    y = np.reshape(np.arange(0,N, dtype=np.float32), (N,1))\n",
    "    \n",
    "    \n",
    "    X_train, y_train = X[:N_train], y[:N_train]\n",
    "    X_test, y_test = X[N_train:], y[N_train:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = generate_data(N, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        N = X.shape[0]        \n",
    "        self.N = N\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = np.expand_dims(self.X[index], -1)\n",
    "        y = self.y[index]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_lstm_layers, batch_size,\n",
    "                seq_len, window_size, step=1):\n",
    "        super(Net, self).__init__()        \n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.window_size = window_size\n",
    "        self.step = 1\n",
    "        self.lstm1 = nn.LSTM(input_size=1, hidden_size=num_hidden, \n",
    "                             num_layers=num_lstm_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(num_hidden, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.hidden = list()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        self.hidden = [(Variable(torch.zeros(self.num_lstm_layers, self.batch_size, self.num_hidden, dtype=torch.float32)), \n",
    "                       Variable(torch.zeros(self.num_lstm_layers, self.batch_size, self.num_hidden, dtype=torch.float32)))]\n",
    "    \n",
    "    def forward(self, batch_data):\n",
    "        num_steps = self.seq_len - self.window_size + 1\n",
    "        w = self.window_size\n",
    "        for i in range(num_steps):            \n",
    "            x = batch_data[:,i:i+w]        \n",
    "            lstm_out, h = self.lstm1(x, self.hidden[-1])\n",
    "            self.hidden.append(h)\n",
    "            \n",
    "        \n",
    "        y_pred = self.sigmoid(self.fc1(lstm_out[:,-1]))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "train_ds = SequenceDataset(X_train, y_train)\n",
    "train_dataloader = utils.DataLoader(train_ds, batch_size=batch_size, drop_last=True)\n",
    "net = Net(num_features=1, num_hidden=64, num_lstm_layers=1, batch_size=batch_size,\n",
    "         seq_len=seq_len, window_size=window_size)\n",
    "learning_rate = 1e-3\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "test_ds = SequenceDataset(X_test, y_test)\n",
    "test_dataloader = utils.DataLoader(test_ds, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Training loss:  0.021014215238392354 , Training accuracy:  0.6114583333333333\n",
      "Test loss:  0.020621426669614657 , Test accuracy:  0.6294642857142857\n",
      "Epoch  1\n",
      "Training loss:  0.020915064339836437 , Training accuracy:  0.6114583333333333\n",
      "Test loss:  0.020664540784699575 , Test accuracy:  0.6294642857142857\n",
      "Epoch  2\n",
      "Training loss:  0.020886693087716898 , Training accuracy:  0.6114583333333333\n",
      "Test loss:  0.02062721018280302 , Test accuracy:  0.6294642857142857\n",
      "Epoch  3\n",
      "Training loss:  0.020887828307847182 , Training accuracy:  0.6114583333333333\n",
      "Test loss:  0.020625903936369077 , Test accuracy:  0.6294642857142857\n",
      "Epoch  4\n",
      "Training loss:  0.020163585276653368 , Training accuracy:  0.6114583333333333\n",
      "Test loss:  0.012450687055076872 , Test accuracy:  0.6294642857142857\n",
      "Epoch  5\n",
      "Training loss:  0.0064618337356174985 , Training accuracy:  0.940625\n",
      "Test loss:  0.0019450946544696177 , Test accuracy:  1.0\n",
      "Epoch  6\n",
      "Training loss:  0.0014286195548872153 , Training accuracy:  1.0\n",
      "Test loss:  0.0009040727413126401 , Test accuracy:  1.0\n",
      "Epoch  7\n",
      "Training loss:  0.0007107640946439157 , Training accuracy:  1.0\n",
      "Test loss:  0.0004979926743544638 , Test accuracy:  1.0\n",
      "Epoch  8\n",
      "Training loss:  0.0004194877066765912 , Training accuracy:  1.0\n",
      "Test loss:  0.0003187129955871829 , Test accuracy:  1.0\n",
      "Epoch  9\n",
      "Training loss:  0.0002816855024623995 , Training accuracy:  1.0\n",
      "Test loss:  0.00022554529173898378 , Test accuracy:  1.0\n",
      "Epoch  10\n",
      "Training loss:  0.00020563378881585475 , Training accuracy:  1.0\n",
      "Test loss:  0.00017030944374190376 , Test accuracy:  1.0\n",
      "Epoch  11\n",
      "Training loss:  0.00015856951310221727 , Training accuracy:  1.0\n",
      "Test loss:  0.00013441835264010088 , Test accuracy:  1.0\n",
      "Epoch  12\n",
      "Training loss:  0.00012704897211127293 , Training accuracy:  1.0\n",
      "Test loss:  0.00010954480863542162 , Test accuracy:  1.0\n",
      "Epoch  13\n",
      "Training loss:  0.0001047131952266985 , Training accuracy:  1.0\n",
      "Test loss:  9.146737595853795e-05 , Test accuracy:  1.0\n",
      "Epoch  14\n",
      "Training loss:  8.820214970910456e-05 , Training accuracy:  1.0\n",
      "Test loss:  7.784200196121154e-05 , Test accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    tr_acc = 0\n",
    "    tr_loss = 0\n",
    "    total = 0\n",
    "    for batch_data, batch_labels in train_dataloader:\n",
    "        net.init_hidden()        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = net(batch_data)\n",
    "        loss = loss_fn(y_pred, batch_labels)\n",
    "        tr_loss += loss.item()\n",
    "        mean_tr_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total += batch_size\n",
    "        \n",
    "        y_pred = (y_pred > 0.5).type(torch.FloatTensor)\n",
    "        accuracy = (y_pred == batch_labels).sum().item()\n",
    "        tr_acc += accuracy\n",
    "        \n",
    "        \n",
    "    tr_loss = tr_loss/total\n",
    "    tr_acc = tr_acc/total\n",
    "        \n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    total = 0\n",
    "    for batch_data, batch_labels in test_dataloader:\n",
    "        net.init_hidden()\n",
    "        y_pred = net(batch_data)\n",
    "        loss = loss_fn(y_pred, batch_labels)       \n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        y_pred = (y_pred > 0.5).type(torch.FloatTensor)\n",
    "        accuracy = (y_pred == batch_labels).sum().item()\n",
    "        test_acc += accuracy\n",
    "        \n",
    "        total += batch_size\n",
    "    \n",
    "    test_loss = test_loss/total\n",
    "    test_acc = test_acc/total\n",
    "    print(\"Epoch \", epoch)\n",
    "    print(\"Training loss: \", tr_loss, \", Training accuracy: \", tr_acc)\n",
    "    print(\"Test loss: \", test_loss, \", Test accuracy: \", test_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\shaur\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(units=64, stateful=True, batch_input_shape=(batch_size, window_size, num_features)))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss 0.6696522831916809, Training accuracy : 0.6104166507720947\n",
      "Training loss 0.37252891063690186, Training accuracy : 0.8138889074325562\n",
      "Training loss 0.002142030280083418, Training accuracy : 1.0\n",
      "Training loss 0.0007593360496684909, Training accuracy : 1.0\n",
      "Training loss 0.0004327250935602933, Training accuracy : 1.0\n",
      "Training loss 0.0002880175889004022, Training accuracy : 1.0\n",
      "Training loss 0.0002076311211567372, Training accuracy : 1.0\n",
      "Training loss 0.00015851126227062196, Training accuracy : 1.0\n",
      "Training loss 0.00012558502203319222, Training accuracy : 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-9decd8fc779c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mmean_tr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmean_tr_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3050\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ds = SequenceDataset(X_train, y_train)\n",
    "train_dataloader = utils.DataLoader(ds, batch_size=batch_size, drop_last=True)\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_data, batch_label in train_dataloader:\n",
    "        \n",
    "        model.reset_states()\n",
    "\n",
    "        batch_data, batch_label = ds.get_batch()            \n",
    "        loss, acc = model.train_on_batch(batch_data, batch_label)\n",
    "        mean_tr_loss.append(loss)\n",
    "        mean_tr_acc.append(acc)\n",
    "    print('Training loss {}, Training accuracy : {}'.format(np.mean(mean_tr_loss), np.mean(mean_tr_acc)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = X_test[:224]\n",
    "y_test_ = y_test[:224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = StatefulSequenceDataset(X_test_, y_test_, batch_size=32,seq_len=seq_len, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = test_ds.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_states()\n",
    "model.predict_on_batch(np.expand_dims(xx,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.init_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(xx.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
