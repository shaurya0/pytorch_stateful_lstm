{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "from time import sleep\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1200\n",
    "batch_size = 32\n",
    "seq_len = 20\n",
    "num_features = 1\n",
    "window_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, seq_len):\n",
    "    N_train = int(N*0.8)\n",
    "    X = np.zeros((N, seq_len), dtype=np.float32)\n",
    "    y = np.zeros((N,1), dtype=np.float32)\n",
    "    \n",
    "    indices = np.random.randint(0, N, size=N//2)\n",
    "    \n",
    "    X[indices, 0] = 1.0\n",
    "    y[indices, 0] = 1.0\n",
    "    \n",
    "    X_train, y_train = X[:N_train], y[:N_train]\n",
    "    X_test, y_test = X[N_train:], y[N_train:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_test_data(N, seq_len):\n",
    "    N_train = int(N*0.8)\n",
    "    X = np.reshape(np.arange(0, N*seq_len, dtype=np.float32),(N, seq_len))\n",
    "    y = np.reshape(np.arange(0,N, dtype=np.float32), (N,1))\n",
    "    \n",
    "    \n",
    "    X_train, y_train = X[:N_train], y[:N_train]\n",
    "    X_test, y_test = X[N_train:], y[N_train:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = generate_data(N, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatefulSequenceDataset(object):\n",
    "    def __init__(self, X, y, batch_size, seq_len, window_size):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.window_size = window_size\n",
    "        N = X.shape[0]\n",
    "        \n",
    "        assert(N%batch_size == 0)\n",
    "        assert(seq_len >= window_size)\n",
    "        self.N = N\n",
    "        \n",
    "        # index into X,y matrices, ranges from 0:(N - batch_size)\n",
    "        self.idx = 0\n",
    "        \n",
    "        # index into subsequence, ranges from 0:window_size\n",
    "        self.subseq_idx = 0\n",
    "        self.subseq_len = self.seq_len - self.window_size\n",
    "        \n",
    "    \n",
    "    def get_batch(self):\n",
    "        if self.subseq_idx == self.num_batches_per_sequence():\n",
    "            self.idx = (self.idx + self.batch_size) % self.N\n",
    "            self.subseq_idx = 0\n",
    "        \n",
    "        ii = self.idx\n",
    "        bs = self.batch_size\n",
    "        \n",
    "        jj = self.subseq_idx\n",
    "        batch_X = self.X[ii:ii+bs, jj:jj+self.window_size]        \n",
    "        batch_y = self.y[ii:ii+bs]\n",
    "        \n",
    "        self.subseq_idx += 1\n",
    "        return batch_X, batch_y\n",
    "    \n",
    "    def num_batches_per_epoch(self):\n",
    "        return self.N//self.batch_size\n",
    "    \n",
    "    def num_batches_per_sequence(self):\n",
    "        return (self.seq_len - self.window_size) + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_lstm_layers, batch_size):\n",
    "        super(Net, self).__init__()        \n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_lstm_layers = num_lstm_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm1 = nn.LSTM(input_size=1, hidden_size=num_hidden, \n",
    "                             num_layers=num_lstm_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(num_hidden, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.hidden = list()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        self.hidden = (Variable(torch.zeros(self.num_lstm_layers, self.batch_size, self.num_hidden, dtype=torch.float32)), \n",
    "                       Variable(torch.zeros(self.num_lstm_layers, self.batch_size, self.num_hidden, dtype=torch.float32)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm1(x, self.hidden)\n",
    "        \n",
    "        y_pred = self.sigmoid(self.fc1(lstm_out[:,-1]))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = StatefulSequenceDataset(X_train, y_train, batch_size, seq_len, window_size)\n",
    "num_epochs = 15\n",
    "net = Net(num_features=1, num_hidden=64, num_lstm_layers=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 loss:  3.8551025390625 training accuracy:  tensor(0.5958)\n",
      "Epoch  1 loss:  3.8316895961761475 training accuracy:  tensor(0.6104)\n",
      "Epoch  2 loss:  3.8298394680023193 training accuracy:  tensor(0.6104)\n",
      "Epoch  3 loss:  3.8272664546966553 training accuracy:  tensor(0.6104)\n",
      "Epoch  4 loss:  3.8250417709350586 training accuracy:  tensor(0.6104)\n",
      "Epoch  5 loss:  3.823786497116089 training accuracy:  tensor(0.6104)\n",
      "Epoch  6 loss:  3.8224081993103027 training accuracy:  tensor(0.6104)\n",
      "Epoch  7 loss:  3.8214097023010254 training accuracy:  tensor(0.6104)\n",
      "Epoch  8 loss:  3.8204801082611084 training accuracy:  tensor(0.6104)\n",
      "Epoch  9 loss:  3.819725513458252 training accuracy:  tensor(0.6104)\n",
      "Epoch  10 loss:  3.8192384243011475 training accuracy:  tensor(0.6104)\n",
      "Epoch  11 loss:  3.8180665969848633 training accuracy:  tensor(0.6104)\n",
      "Epoch  12 loss:  2.90254807472229 training accuracy:  tensor(0.6264)\n",
      "Epoch  13 loss:  0.02285894565284252 training accuracy:  tensor(1.)\n",
      "Epoch  14 loss:  0.01003650389611721 training accuracy:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "hist = list()\n",
    "for epoch in range(num_epochs):\n",
    "    acc = 0\n",
    "    for _ in range(ds.num_batches_per_epoch()):\n",
    "        net.init_hidden()\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        for _ in range(ds.num_batches_per_sequence()):\n",
    "            batch_data, batch_labels = ds.get_batch()\n",
    "            batch_data = batch_data.unsqueeze(-1)\n",
    "            y_pred = net(batch_data)\n",
    "            loss += loss_fn(y_pred, batch_labels)\n",
    "            \n",
    "            acc += (torch.sum((y_pred> 0.5).type(torch.FloatTensor) == batch_labels).type(torch.FloatTensor)/float(batch_size))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    mean_acc = acc/(ds.num_batches_per_epoch()*ds.num_batches_per_sequence())\n",
    "\n",
    "    \n",
    "    print(\"Epoch \", epoch, \"loss: \", loss.item(), \"training accuracy: \", mean_acc)\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(units=64, stateful=True, batch_input_shape=(batch_size, window_size, num_features)))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss 0.6578120589256287, Training accuracy : 0.6875\n",
      "Training loss 0.0060275159776210785, Training accuracy : 1.0\n",
      "Training loss 0.0018513464601710439, Training accuracy : 1.0\n",
      "Training loss 0.0009371936903335154, Training accuracy : 1.0\n",
      "Training loss 0.000610446382779628, Training accuracy : 1.0\n",
      "Training loss 0.00043657628702931106, Training accuracy : 1.0\n",
      "Training loss 0.0003327868180349469, Training accuracy : 1.0\n",
      "Training loss 0.0002634057018440217, Training accuracy : 1.0\n",
      "Training loss 0.00021345158165786415, Training accuracy : 1.0\n",
      "Training loss 0.00017565298185218126, Training accuracy : 1.0\n",
      "Training loss 0.0001462977525079623, Training accuracy : 1.0\n",
      "Training loss 0.00012370476906653494, Training accuracy : 1.0\n",
      "Training loss 0.00010554552864050493, Training accuracy : 1.0\n",
      "Training loss 9.085427882382646e-05, Training accuracy : 1.0\n",
      "Training loss 7.884090155130252e-05, Training accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "ds = StatefulSequenceDataset(X_train, y_train, batch_size, seq_len, window_size)\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for _ in range(ds.num_batches_per_epoch()):\n",
    "        model.reset_states()\n",
    "        mean_tr_acc = []\n",
    "        mean_tr_loss = []\n",
    "        for _ in range(ds.num_batches_per_sequence()):\n",
    "            batch_data, batch_label = ds.get_batch()\n",
    "            batch_data = np.expand_dims(batch_data, -1)\n",
    "            loss, acc = model.train_on_batch(batch_data, batch_label)\n",
    "            mean_tr_loss.append(loss)\n",
    "            mean_tr_acc.append(acc)\n",
    "    print('Training loss {}, Training accuracy : {}'.format(np.mean(mean_tr_loss), np.mean(mean_tr_acc)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ = X_test[:224]\n",
    "y_test_ = y_test[:224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = StatefulSequenceDataset(X_test_, y_test_, batch_size=32,seq_len=seq_len, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = test_ds.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05],\n",
       "       [9.9985719e-01],\n",
       "       [7.7694574e-05],\n",
       "       [7.7694574e-05]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reset_states()\n",
    "model.predict_on_batch(np.expand_dims(xx,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.init_hidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.0002],\n",
       "        [0.9995],\n",
       "        [0.0002],\n",
       "        [0.0002]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(xx.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
